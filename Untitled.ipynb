{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86544c67",
   "metadata": {},
   "source": [
    "!pip -q install trax\n",
    "!pip install t5\n",
    "!pip install -U jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb0e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 18:19:15.056319: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import t5\n",
    "import numpy as np\n",
    "import trax\n",
    "import gc\n",
    "import time\n",
    "from trax.supervised import decoding\n",
    "from numba import cuda \n",
    "import textwrap \n",
    "# Will come handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3acd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, EOS, UNK = 0, 1, 2\n",
    "\n",
    "def detokenize(np_array):\n",
    "    return trax.data.detokenize(\n",
    "    np_array,\n",
    "    vocab_type = 'sentencepiece',\n",
    "    vocab_file = 'sentencepiece.model',\n",
    "    vocab_dir =\"./\")\n",
    "\n",
    "def tokenize(s):\n",
    "  # The trax.data.tokenize function operates on streams,\n",
    "  # that's why we have to create 1-element stream with iter\n",
    "  # and later retrieve the result with next.\n",
    "  return next(trax.data.tokenize(\n",
    "      iter([s]),\n",
    "      vocab_type = 'sentencepiece',\n",
    "      vocab_file = 'sentencepiece.model',\n",
    "      vocab_dir = \"./\"))\n",
    " \n",
    "vocab_size = trax.data.vocab_size(\n",
    "    vocab_type = 'sentencepiece',\n",
    "    vocab_file = 'sentencepiece.model',\n",
    "    vocab_dir = \"./\")\n",
    "\n",
    "def get_sentinels(vocab_size):\n",
    "    sentinels = {}\n",
    "\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "\n",
    "        decoded_text = detokenize([vocab_size - i]) \n",
    "        \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'\n",
    "        \n",
    "    return sentinels\n",
    "\n",
    "sentinels = get_sentinels(vocab_size)    \n",
    "\n",
    "\n",
    "def pretty_decode(encoded_str_list, sentinels=sentinels):\n",
    "    # If already a string, just do the replacements.\n",
    "    if isinstance(encoded_str_list, (str, bytes)):\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = encoded_str_list.replace(token, char)\n",
    "        return encoded_str_list\n",
    "  \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(detokenize(encoded_str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e282e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model = trax.models.Transformer(\n",
    "    d_ff = 4096,\n",
    "    d_model = 1024,\n",
    "    max_len = 2048,\n",
    "    n_heads = 16,\n",
    "    dropout = 0.1,\n",
    "    input_vocab_size = 32000,\n",
    "    n_encoder_layers = 24,\n",
    "    n_decoder_layers = 24,\n",
    "    mode='predict')  # Change to 'eval' for slow decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd82f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: DeprecationWarning: in the future the `.dtype` attribute of a given datatype object must be a valid dtype instance. `data_type.dtype` may need to be coerced using `np.dtype(data_type.dtype)`. (Deprecated NumPy 1.20)\n"
     ]
    }
   ],
   "source": [
    "# load in the model\n",
    "# this will take a minute\n",
    "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)\n",
    "model.init_from_file('./model_squad.pkl.gz',\n",
    "                     weights_only=True, input_signature=(shape11, shape11))\n",
    "empty_state = model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860cb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  822    10   125   405     3 11599  2116    58  2625    10 22139    19\n",
      "     8   793  2056    24  2116  1052     6   165  4431 17429     7     6\n",
      "   165  4644    11  3889   190   628    11    97     6    11     8  1341\n",
      " 12311    13   827    11  2054     5 22139    19    80    13     8   167\n",
      "  4431  4290 15015     6    28   165   711  1288   271    12   734   149\n",
      "     8  8084 19790     7     5  6306   115   908  6306   519   908  6306\n",
      "   591   908  6306   755   908    71 17901   113     3 17095    16     8\n",
      "  1057    13     3 11599    19   718     3     9     3  6941     7   447\n",
      "   343     5 22139    19    80    13     8 10043  2705 15015    11     6\n",
      "   190   165 11980    13     3 12466    63     6  2361     8 10043     5\n",
      " 23847   231    13     8   657   192  3293    35    29    23     9     6\n",
      "     3 11599     6     3 11366     6 15651     6    11   824  9678    13\n",
      " 17082   130     3     9   294    13   793  8156     6    68   383     8\n",
      " 19268 12197    16     8  1003   189  2646   175   793 13554 13999    38\n",
      "   775   585 14310     7    16    70   293   269     5 22139 27806     7\n",
      "    28   186     3    23 25503   844    13   585     6   224    38  2392\n",
      " 11599    11 21353     3 11366     6    11     8 11814    13     3 11599\n",
      "    33    59 13987   120  4802     5   368   912    16     3 11599   557\n",
      "  3209     8  4431 12009  7463    57   119 13554    11  3130   126 18836\n",
      "     7    13   585    16   175    11   119  2705 15015   224    38 17082\n",
      "    11  8156     5]\n"
     ]
    }
   ],
   "source": [
    "# an extensive example\n",
    "inputs = '''question: when doesthe definiton of thermodynamics was stated? context: Historically, thermodynamics developed out of a desire to increase the efficiency of early steam engines, particularly through the work of French physicist Sadi Carnot (1824) who believed that engine efficiency was the key that could help France win the Napoleonic Wars.[1] Scots-Irish physicist Lord Kelvin was the first to formulate a concise definition of thermodynamics in 1854'''\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "print(tokenize(inputs))\n",
    "test_inputs = tokenize(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582bd10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its fundamental constituents\n",
      "--- command took 9.610665559768677 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "output = decoding.autoregressive_sample(model, inputs=np.array(test_inputs)[None, :],\n",
    "                                        temperature=0.0, max_length=100, accelerate=False, eval_mode=False)\n",
    "print(wrapper.fill(pretty_decode(output[0])))\n",
    "end_time=time.time()\n",
    "print(\"--- command took %s seconds ---\" % (time.time() - start_time))\n",
    "model.state = empty_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d04094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
